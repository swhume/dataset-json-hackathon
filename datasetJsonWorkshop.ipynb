{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset-JSON Workshop Notebook\n",
    "\n",
    "This notebook was developed as part of the PHUSE Dataset-JSON Workshop. It is experimental and meant as an exercise to explore working with Dataset-JSON in Python.\n",
    "\n",
    "This notebook demonstrates reading and writing Dataset-JSON files and validating them against the Dataset-JSON schema. It creates a simple Python Pandas dataframe from the Dataset-JSON file. Other conversions applications, including the notebook created for the initial Dataset-JSON Hackathon provide more detailed dataframe conversion (e.g., include datatype conversions). \n",
    "\n",
    "### Import the Python libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccd95cd1e0fdaa7a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from jsonschema import validate\n",
    "from jsonschema.exceptions import ValidationError\n",
    "import requests"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T17:54:26.716439806Z",
     "start_time": "2023-08-18T17:54:26.438185400Z"
    }
   },
   "id": "bc979200ca246e56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Dataset-JSON example file from GitHub\n",
    "\n",
    "Retrieve an example Dataset-JSON file from the CDISC DataExchange-Dataset-Json repository and write the file in a local data directory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed50d6e2ed324dd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_file = 'data/vs.json'\n",
    "try:\n",
    "    r = requests.get('https://github.com/cdisc-org/DataExchange-DatasetJson/blob/master/examples/sdtm/vs.json?raw=True')\n",
    "    r.raise_for_status()\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    raise SystemExit(err)\n",
    "with open(data_file, 'w') as f:\n",
    "    json.dump(r.json(), f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T17:54:29.330294905Z",
     "start_time": "2023-08-18T17:54:28.671866968Z"
    }
   },
   "id": "694b5b69e8dc1438"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Dataset-JSON schema file from GitHub\n",
    "\n",
    "Retrieve the Dataset-JSON schema file from the CDISC DataExchange-Dataset-Json repository and write the file in a local data directory."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25c965227448420e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "schema_file = 'data/dataset-json-schema.json'\n",
    "try:\n",
    "    r = requests.get('https://github.com/cdisc-org/DataExchange-DatasetJson/blob/master/schema/dataset.schema.json?raw=True')\n",
    "    r.raise_for_status()\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    raise SystemExit(err)\n",
    "with open(schema_file, 'w') as f:\n",
    "    json.dump(r.json(), f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T17:54:33.611942680Z",
     "start_time": "2023-08-18T17:54:33.014127386Z"
    }
   },
   "id": "1159b087e82ee1e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and Validate Dataset-JSON File\n",
    "For smaller datasets, simply load data using json module. This loads the entire file into memory so may not work for very large datasets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537c29aa814275e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/vs.json is valid\n"
     ]
    }
   ],
   "source": [
    "with open(data_file, 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "with open(schema_file, 'r') as f:\n",
    "    dsj_schema = json.loads(f.read())\n",
    "\n",
    "try:\n",
    "    validate(instance=data, schema=dsj_schema)\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation error in {data_file}: {e}\")\n",
    "else:\n",
    "    print(f\"{data_file} is valid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T17:54:36.882337223Z",
     "start_time": "2023-08-18T17:54:36.611805032Z"
    }
   },
   "id": "2e49b1f55f9da11f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load and Validate Invalid Dataset-JSON File\n",
    "This version of the VS Dataset-JSON dataset is missing the required \"datasetJSONVersion\" attribute making it invalid. Validating this version of the VS dataset against the schema produces a validation error."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99930a671b67d138"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error in data/vs-invalid.json: 'datasetJSONVersion' is a required property\n"
     ]
    }
   ],
   "source": [
    "invalid_data_file = 'data/vs-invalid.json'\n",
    "with open(invalid_data_file, 'r') as f:\n",
    "    invalid_dataset = json.loads(f.read())\n",
    "\n",
    "try:\n",
    "    validate(instance=invalid_dataset, schema=dsj_schema)\n",
    "except ValidationError as e:\n",
    "    print(f\"Validation error in {invalid_data_file}: {e.message}\")\n",
    "else:\n",
    "    print(f\"{invalid_data_file} is valid\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T18:05:52.140629274Z",
     "start_time": "2023-08-18T18:05:51.916398144Z"
    }
   },
   "id": "8f266edfaa575be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show Dataset Metadata\n",
    "Show the name and label for the dataset as well as all the variables names that will be used as column headings. Also, load the data types from the Dataset-JSON file to set the data types in the Pandas dataframe."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a75b5f56245f1657"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: VS (Vital Signs)\n",
      "\n",
      "Variables: ITEMGROUPDATASEQ, STUDYID, DOMAIN, USUBJID, VSSEQ, VSTESTCD, VSTEST, VSPOS, VSORRES, VSORRESU, VSSTRESC, VSSTRESN, VSSTRESU, VSSTAT, VSLOC, VSLOBXFL, VSREPNUM, VISITNUM, VISIT, EPOCH, VSDTC, VSDY\n"
     ]
    }
   ],
   "source": [
    "dataset_attrs = list(data[\"clinicalData\"][\"itemGroupData\"].values())[0]\n",
    "print(f\"Name: {dataset_attrs['name']} ({dataset_attrs['label']})\", end='\\n\\n')\n",
    "variables = [var['name'] for var in dataset_attrs['items']]\n",
    "print(f\"Variables: {', '.join([var_name for var_name in variables])}\")\n",
    "data_types = [var['type'] for var in dataset_attrs['items']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T19:01:56.728183417Z",
     "start_time": "2023-08-18T19:01:56.681238907Z"
    }
   },
   "id": "dfb5dbf09148b1b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a dataframe from the Dataset-JSON file\n",
    "Create a dataframe from the Dataset-JSON file. Then print the top 5 rows and provide the memory usage for the dataframe. Then save the dataframe as a CSV file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fa0022a069c3b1b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ITEMGROUPDATASEQ       STUDYID DOMAIN   USUBJID  VSSEQ VSTESTCD  \\\n",
      "0                 1  CDISCPILOT01     VS  CDISC001      1    DIABP   \n",
      "1                 2  CDISCPILOT01     VS  CDISC001      2    DIABP   \n",
      "2                 3  CDISCPILOT01     VS  CDISC001      3    DIABP   \n",
      "3                 4  CDISCPILOT01     VS  CDISC001      4    DIABP   \n",
      "4                 5  CDISCPILOT01     VS  CDISC001      5    DIABP   \n",
      "\n",
      "                     VSTEST     VSPOS VSORRES VSORRESU  ... VSSTRESU  VSSTAT  \\\n",
      "0  Diastolic Blood Pressure  STANDING      71     mmHg  ...     mmHg           \n",
      "1  Diastolic Blood Pressure  STANDING      71     mmHg  ...     mmHg           \n",
      "2  Diastolic Blood Pressure  STANDING      83     mmHg  ...     mmHg           \n",
      "3  Diastolic Blood Pressure  STANDING      79     mmHg  ...     mmHg           \n",
      "4  Diastolic Blood Pressure  STANDING      68     mmHg  ...     mmHg           \n",
      "\n",
      "  VSLOC VSLOBXFL VSREPNUM VISITNUM        VISIT      EPOCH       VSDTC VSDY  \n",
      "0                     NaN        1  SCREENING 1  SCREENING  2012-11-23   -7  \n",
      "1                     NaN        2  SCREENING 2  SCREENING  2012-11-28   -2  \n",
      "2              Y      NaN        3     BASELINE  SCREENING  2012-11-30    1  \n",
      "3                     NaN        4       WEEK 2  TREATMENT  2012-12-13   14  \n",
      "4                     NaN        5       WEEK 4  TREATMENT  2012-12-26   27  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "\n",
      "dataframe memory usage: 248992 bytes\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset_attrs['itemData'], columns=variables)\n",
    "print(df.head(5), end='\\n\\n')\n",
    "print(f\"\\ndataframe memory usage: {df.memory_usage().sum()} bytes\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T19:01:59.452597065Z",
     "start_time": "2023-08-18T19:01:59.426491970Z"
    }
   },
   "id": "a200b2ffb1fccf52"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write the newly created dataset as a CSV file."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "816f5b8e49d388e9"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df.to_csv('data/' + dataset_attrs['name'] + '.csv', index=False, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-18T19:02:02.081451641Z",
     "start_time": "2023-08-18T19:02:02.065612636Z"
    }
   },
   "id": "a4638c489a5de2c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
